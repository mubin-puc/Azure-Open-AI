{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# API Search - Make our bot to talk to any API"
      ],
      "metadata": {},
      "id": "66ab3cc5-aee4-415a-9391-1e5d37ccaf1d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have observed the remarkable synergy created by combining **GPT-4 with intelligent agents and detailed prompts**. This powerful combination has consistently delivered impressive results. To further capitalize on this capability, we should aim to integrate it with various systems through API communication. Essentially, we can develop within this notebook what is referred to in OpenAI's ChatGPT as 'GPTs.'\n",
        "\n",
        "Envision a bot that seamlessly integrates with:\n",
        "\n",
        "- **CRM Systems:** Including Dynamics, Salesforce, and HubSpot.\n",
        "- **ERP Systems:** Such as SAP, Dynamics, and Oracle.\n",
        "- **CMS Systems:** Including Adobe, Oracle, and other content management platforms.\n",
        "\n",
        "The objective is to connect our bot with data repositories, minimizing data duplication as much as possible. These systems typically offer APIs, facilitating programmatic data access.\n",
        "\n",
        "In this notebook, we plan to develop an agent capable of querying an API to retrieve information and effectively answer questions. We will maintain our focus on the COVID-19 theme and interact with the Open Disease Data API (https://disease.sh/)."
      ],
      "metadata": {},
      "id": "306fc0a9-4044-441d-9ba7-f54f32e6ea9f"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "from time import sleep\n",
        "from typing import Dict, List\n",
        "from pydantic import BaseModel, Extra, root_validator\n",
        "\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.tools import BaseTool\n",
        "from langchain.requests import RequestsWrapper\n",
        "from langchain.chains import APIChain\n",
        "from langchain.agents.agent_toolkits.openapi.spec import reduce_openapi_spec\n",
        "\n",
        "from common.callbacks import StdOutCallbackHandler\n",
        "from common.utils import num_tokens_from_string, reduce_openapi_spec\n",
        "from common.prompts import APISEARCH_PROMPT_PREFIX\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string.replace(\"$\",\"USD \")))\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1703782896153
        }
      },
      "id": "c1fb79a3-4856-4721-988c-112813690a90"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1703782896373
        }
      },
      "id": "258a6e99-2d4f-4147-b8ee-c64c85296181"
    },
    {
      "cell_type": "code",
      "source": [
        "cb_handler = StdOutCallbackHandler()\n",
        "cb_manager = CallbackManager(handlers=[cb_handler])\n",
        "\n",
        "llm_1 = AzureChatOpenAI(deployment_name=\"gpt-4-32k\", temperature=0, max_tokens=2000, callback_manager=cb_manager)\n",
        "llm_2 = AzureChatOpenAI(deployment_name=\"gpt-35-turbo-16k\", temperature=0, max_tokens=1000)\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1703782896641
        }
      },
      "id": "9d3daf03-77e2-466e-a255-2f06bee3561b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Logic"
      ],
      "metadata": {},
      "id": "9cc03401-a5a9-455b-bf17-07da2005e61f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "By now, you must infer that the solution for an API Agent has to be something like: give the API specification as part of the system prompt to the LLM , then have an agent plan for the right steps to formulate the API call.<br>\n",
        "\n",
        "Let's do that. But we must first understand the industry standards of Swagger/OpenAPI\n"
      ],
      "metadata": {},
      "id": "ebe42eda-3e74-4114-bd25-2473593cc1b4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to OpenAPI (formerly Swagger)"
      ],
      "metadata": {},
      "id": "1e8e0b32-a6b5-4b1c-943d-e57b737213fa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The OpenAPI Specification, previously known as the Swagger Specification, is a specification for a machine-readable interface definition language for describing, producing, consuming and visualizing web services. Previously part of the Swagger framework, it became a separate project in 2016, overseen by the OpenAPI Initiative, an open-source collaboration project of the Linux Foundation.\n",
        "\n",
        "OpenAPI Specification is an API description format for REST APIs. An OpenAPI file allows you to describe your entire API, including: Available endpoints (/users for example) and operations on each endpoint ( GET /users, POST /users), description, contact information, license, terms of use and other information."
      ],
      "metadata": {},
      "id": "003327ac-2851-48ef-8a6b-2d8c2004bb2e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's get the OpenAPI (Swagger) spec from our desired API that we want to talk to"
      ],
      "metadata": {},
      "id": "a1902af5-f889-4bcf-85e0-1b601bd2ce47"
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://disease.sh/apidocs/swagger_v3.json'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    spec = response.json()\n",
        "else:\n",
        "    spec = None\n",
        "    print(f\"Failed to retrieve data: Status code {response.status_code}\")\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1703782897387
        }
      },
      "id": "e78960a6-623d-4999-a4e3-89aee5c076de"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how big is this API specification:"
      ],
      "metadata": {},
      "id": "dd3cab16-e71d-4652-ab27-7b0704365454"
    },
    {
      "cell_type": "code",
      "source": [
        "# You can check the function \"reduce_openapi_spec()\" in utils.py\n",
        "reduced_api_spec = reduce_openapi_spec(spec)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1703782897590
        }
      },
      "id": "94503afc-c398-458a-b369-610c5dbe682d"
    },
    {
      "cell_type": "code",
      "source": [
        "api_tokens = num_tokens_from_string(str(spec))\n",
        "print(\"API spec size in tokens:\",api_tokens)\n",
        "api_tokens = num_tokens_from_string(str(reduced_api_spec))\n",
        "print(\"Reduced API spec size in tokens:\",api_tokens)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "API spec size in tokens: 12855\nReduced API spec size in tokens: 8772\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1703782898070
        }
      },
      "id": "57d77e9b-6f3f-4ec4-bc01-baac18984937"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes it makes sense to reduce the size of the API Specs by using the `reduce_openapi_spec` function. It's optional."
      ],
      "metadata": {},
      "id": "d8b95356-587d-43ca-982f-500779078482"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question\n",
        "Let's make a complicated question that requires two distinct API calls to different endpoints:"
      ],
      "metadata": {},
      "id": "9a945386-39eb-405d-9310-3b67c9af77bb"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = '''\n",
        "What is to-date the amount of people tested in Argentina vs USA? \n",
        "Also tell me what is the continent with more covid deaths and what's the count as of today\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1703782898413
        }
      },
      "id": "d020b5de-7ebe-4fb9-9b71-f6c71956149d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use a chain to convert the natural language question to an API request using the API specification in the prompt"
      ],
      "metadata": {},
      "id": "d467f57a-7a03-431a-abe9-ca552e71aed0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use a nice chain in langchain called APIChain"
      ],
      "metadata": {},
      "id": "695c47b3-191a-430d-8691-a255152ffee9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Most of APIs require Authorization tokens, so we construct the headers using a lightweight python request wrapper called RequestsWrapper\n",
        "access_token = \"ABCDEFG123456\" \n",
        "headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
        "requests_wrapper = RequestsWrapper(headers=headers)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1703782898727
        }
      },
      "id": "96731b5f-988b-49ec-a5c3-3a344b7085da"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: Notice that we are using GPT-3.5 (llm_2) below for this chain since it doesn't need too many instructions or reasoning"
      ],
      "metadata": {},
      "id": "1fd6a140-f675-40db-98ad-b5c955a4f7b6"
    },
    {
      "cell_type": "code",
      "source": [
        "chain = APIChain.from_llm_and_api_docs(\n",
        "    llm=llm_2,\n",
        "    api_docs=str(reduced_api_spec),\n",
        "    headers=headers,\n",
        "    verbose=True,\n",
        "    limit_to_domains=[\"https://disease.sh/\"],\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1703782898952
        }
      },
      "id": "426fab6f-ea04-4c07-8211-d9cc5c70ac8e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the prompts on the APIChain class (on to create the URL endpoint and the other one to use it and get the answer):"
      ],
      "metadata": {},
      "id": "1707e590-809b-4391-bdcd-c7d285ec8fb1"
    },
    {
      "cell_type": "code",
      "source": [
        "chain.api_request_chain.prompt.template"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1703782899156
        }
      },
      "id": "9f80d2bb-e285-4d30-88c8-5677e86cebe2"
    },
    {
      "cell_type": "code",
      "source": [
        "chain.api_answer_chain.prompt.template"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1703782899500
        }
      },
      "id": "ccc7e9dc-f36b-45e1-867a-1b92d639e941"
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    printmd(chain.run(QUESTION))\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\n\u001b[1m> Entering new APIChain chain...\u001b[0m\n\u001b[32;1m\u001b[1;3mhttps://disease.sh/v3/covid-19/countries/Argentina,USA\u001b[0m\n\u001b[33;1m\u001b[1;3m[{\"updated\":1703782549548,\"country\":\"Argentina\",\"countryInfo\":{\"_id\":32,\"iso2\":\"AR\",\"iso3\":\"ARG\",\"lat\":-34,\"long\":-64,\"flag\":\"https://disease.sh/assets/img/flags/ar.png\"},\"cases\":10080046,\"todayCases\":0,\"deaths\":130685,\"todayDeaths\":0,\"recovered\":9949361,\"todayRecovered\":0,\"active\":0,\"critical\":0,\"casesPerOneMillion\":219083,\"deathsPerOneMillion\":2840,\"tests\":35716069,\"testsPerOneMillion\":776264,\"population\":46010234,\"continent\":\"South America\",\"oneCasePerPeople\":5,\"oneDeathPerPeople\":352,\"oneTestPerPeople\":1,\"activePerOneMillion\":0,\"recoveredPerOneMillion\":216242.35,\"criticalPerOneMillion\":0},{\"updated\":1703782549471,\"country\":\"USA\",\"countryInfo\":{\"_id\":840,\"iso2\":\"US\",\"iso3\":\"USA\",\"lat\":38,\"long\":-97,\"flag\":\"https://disease.sh/assets/img/flags/us.png\"},\"cases\":110057289,\"todayCases\":0,\"deaths\":1190019,\"todayDeaths\":0,\"recovered\":107829742,\"todayRecovered\":0,\"active\":1037528,\"critical\":1754,\"casesPerOneMillion\":328720,\"deathsPerOneMillion\":3554,\"tests\":1186546440,\"testsPerOneMillion\":3543990,\"population\":334805269,\"continent\":\"North America\",\"oneCasePerPeople\":3,\"oneDeathPerPeople\":281,\"oneTestPerPeople\":0,\"activePerOneMillion\":3098.9,\"recoveredPerOneMillion\":322067.04,\"criticalPerOneMillion\":5.24}]\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "To-date, the amount of people tested in Argentina is 35,716,069, while in the USA it is 1,186,546,440. \n\nThe continent with the most COVID deaths as of today is North America, with a total count of 1,190,019 deaths."
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1703782902123
        }
      },
      "id": "d7f60335-5551-4ee0-ba4e-1cd84f3a9f48"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have seen before in prior notebooks, a single chain cannot reason/observe/think, so it cannot figure out that it needs to call two endpoints in order to get the continents information. As you will see below, North America is NOT the continent with the highest amount of deaths."
      ],
      "metadata": {},
      "id": "70d364b5-b7f8-4f14-8501-187fdda97ecd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a custom agent that uses the APIChain as a tool\n",
        "\n",
        "To solve the avobe problem, we can build a REACT Agent that uses the APIChain as a tool to get the information. This agent will create as many calls as needed (using the chain tool) until it answers the question"
      ],
      "metadata": {},
      "id": "2ccdb128-7700-4e37-b378-490051348daa"
    },
    {
      "cell_type": "code",
      "source": [
        "class MyAPISearch(BaseTool):\n",
        "    \"\"\"APIChain as an agent tool\"\"\"\n",
        "    \n",
        "    name = \"@apisearch\"\n",
        "    description = \"useful when the questions includes the term: @apisearch.\\n\"\n",
        "\n",
        "    llm: AzureChatOpenAI\n",
        "    api_spec: str\n",
        "    headers: dict = {}\n",
        "    limit_to_domains: list = []\n",
        "    verbose: bool = False\n",
        "    \n",
        "    def _run(self, query: str) -> str:\n",
        "        \n",
        "        chain = APIChain.from_llm_and_api_docs(\n",
        "                            llm=self.llm,\n",
        "                            api_docs=self.api_spec,\n",
        "                            headers=self.headers,\n",
        "                            verbose=self.verbose,\n",
        "                            limit_to_domains=self.limit_to_domains\n",
        "                            )\n",
        "        try:\n",
        "            sleep(2) # This is optional to avoid possible TPM rate limits\n",
        "            response = chain.run(query)\n",
        "        except Exception as e:\n",
        "            response = e\n",
        "        \n",
        "        return response\n",
        "            \n",
        "    async def _arun(self, query: str) -> str:\n",
        "        \"\"\"Use the tool asynchronously.\"\"\"\n",
        "        raise NotImplementedError(\"This Tool does not support async\")"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1703782902470
        }
      },
      "id": "d3d155ae-16eb-458a-b2ed-5aa9a9b84ed8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice below that we are using GPT-35-Turbo-16k (llm_2) for the Tool and GPT-4-turbo (llm_1) for the Agent"
      ],
      "metadata": {},
      "id": "b553cd34-d9c1-4ec8-858f-f6cc0126bc1e"
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [MyAPISearch(llm=llm_2, api_spec=str(spec), limit_to_domains=[\"https://disease.sh/\"])]\n",
        "agent_executor = initialize_agent(tools, llm_1, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, agent_kwargs={'prefix':APISEARCH_PROMPT_PREFIX}, callback_manager=cb_manager)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1703782902678
        }
      },
      "id": "2c6cf721-76bb-47b6-aeeb-9ff4ff92b1f4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment if you want to see the prompt\n",
        "# printmd(agent_executor.agent.llm_chain.prompt.template)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1703782902871
        }
      },
      "id": "522257ee-9f0c-4260-8713-baf105cea851"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "\n",
        "#As LLMs responses are never the same, we do a for loop in case the answer cannot be parsed according to our prompt instructions\n",
        "for i in range(2):\n",
        "    try:\n",
        "        response = agent_executor.run(QUESTION) \n",
        "        break\n",
        "    except Exception as e:\n",
        "        response = str(e)\n",
        "        continue\n",
        "        \n",
        "printmd(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The user is asking for up-to-date information on the number of people tested for COVID-19 in Argentina and the USA. They also want to know which continent has the highest number of COVID-19 deaths and the current count. I will use the @apisearch tool to find this information.\n\nAction: @apisearch\nAction Input: COVID-19 testing numbers in Argentina and USA\nI have found the number of COVID-19 tests conducted in Argentina and the USA. Now, I need to find out which continent has the highest number of COVID-19 deaths and the current count.\n\nAction: @apisearch\nAction Input: Continent with the highest number of COVID-19 deaths\nI have found the continent with the highest number of COVID-19 deaths, which is Europe. However, I still need to find the current count of deaths in Europe.\n\nAction: @apisearch\nAction Input: Current number of COVID-19 deaths in Europe\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "As of the latest data, Argentina has conducted 35,716,069 COVID-19 tests, while the USA has conducted 1,186,546,440 tests. The continent with the highest number of COVID-19 deaths is Europe, with a current count of 2,090,270 deaths."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 338 ms, sys: 36 ms, total: 374 ms\nWall time: 36.8 s\n"
        }
      ],
      "execution_count": 16,
      "metadata": {},
      "id": "ca910f71-60fb-4758-b4a9-757e37eb421f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Great!!** we have now an API Agent using APIChain as a tool, capable of reasoning until it can find the answer. And it is pretty fast as well."
      ],
      "metadata": {},
      "id": "73027201-d6e2-4aa0-a480-934c53ae4eb8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple APIs\n",
        "\n",
        "What happens if the API is quite basic, meaning it's just a simple endpoint without a Swagger/OpenAPI definition? Let’s consider the following example:\n",
        "\n",
        "[CountdownAPI](https://www.countdownapi.com/) is a streamlined version of the eBay API, available as a paid service. We can test it using their demo query, which does not require any Swagger or OpenAPI specification. In this scenario, our main task is to create a tool that retrieves the results. We then pass these results to an agent for analysis, providing answers to user queries, similar to our approach with the Bing Search agent.\n",
        "\n",
        "An aspect we haven't discussed yet while constructing our API Agent using the APIChain tool is handling situations where either the API specification or the API call results are quite extensive. In such cases, we need to choose between using GPT-4-32k and GPT-4-Turbo.\n",
        "\n",
        "In the example below, there is no API specification, but the response from the API is rather lengthy. For this scenario, we will employ GPT-4-32k."
      ],
      "metadata": {},
      "id": "e9ba3e35-8021-4262-8494-d1aee3862f7e"
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the request parameters\n",
        "params = {\n",
        "  'api_key': 'demo',\n",
        "  'type': 'search',\n",
        "  'ebay_domain': 'ebay.com',\n",
        "  'search_term': 'memory cards'\n",
        "}\n",
        "\n",
        "# make the http GET request to Countdown API\n",
        "api_result = requests.get('https://api.countdownapi.com/request', params)\n",
        "\n",
        "num_tokens = num_tokens_from_string(str(api_result.json())) # this is a custom function we created in common/utils.py\n",
        "print(\"Token count:\",num_tokens,\"\\n\")  \n",
        "\n",
        "# print the first 2000 characters of JSON response from Countdown API\n",
        "print(json.dumps(api_result.json())[:2000], \"...\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Token count: 17521 \n\n{\"request_info\": {\"success\": true, \"demo\": true}, \"request_parameters\": {\"type\": \"search\", \"ebay_domain\": \"ebay.com\", \"search_term\": \"memory cards\"}, \"request_metadata\": {\"ebay_url\": \"https://www.ebay.com/sch/i.html?_nkw=memory+cards&_sacat=0&_dmd=1&_fcid=1\"}, \"search_results\": [{\"position\": 1, \"title\": \"Sandisk 128GB Ultra Plus SDXC UHS-I V10 Card 128G SD HD Class 10 80MB/s\", \"epid\": \"394707482370\", \"link\": \"https://www.ebay.com/itm/394707482370\", \"image\": \"https://i.ebayimg.com/thumbs/images/g/0FEAAOSwByFknCPl/s-l300.jpg\", \"condition\": \"Pre-Owned\", \"seller_info\": {\"name\": \"memory561\", \"review_count\": 106045, \"positive_feedback_percent\": 98.9}, \"is_auction\": false, \"buy_it_now\": false, \"free_returns\": true, \"rating\": 5, \"ratings_total\": 5, \"sponsored\": true, \"prices\": [{\"value\": 9.99, \"raw\": \"$9.99\"}, {\"value\": 499, \"raw\": \"$499.00\"}], \"price\": {\"value\": 9.99, \"raw\": \"$9.99\"}}, {\"position\": 2, \"title\": \"Sandisk Micro SD Card Memory 32GB 64GB 128GB 256GB 512GB 1TB Lot Extreme Ultra\", \"epid\": \"203914554350\", \"link\": \"https://www.ebay.com/itm/203914554350\", \"image\": \"https://i.ebayimg.com/thumbs/images/g/A7wAAOSwemNjTz~l/s-l300.jpg\", \"condition\": \"Brand New\", \"seller_info\": {\"name\": \"terashack\", \"review_count\": 59308, \"positive_feedback_percent\": 100}, \"is_auction\": false, \"buy_it_now\": false, \"free_returns\": true, \"sponsored\": true, \"prices\": [{\"value\": 9.99, \"raw\": \"$9.99\"}, {\"value\": 438.99, \"raw\": \"$438.99\"}], \"price\": {\"value\": 9.99, \"raw\": \"$9.99\"}}, {\"position\": 3, \"title\": \"Sandisk Micro SD Card Ultra TF Memory 32GB 64GB 128GB 256GB 512GB 1TB\", \"epid\": \"203916910977\", \"link\": \"https://www.ebay.com/itm/203916910977\", \"image\": \"https://i.ebayimg.com/thumbs/images/g/THMAAOSwEYliXJ-F/s-l300.jpg\", \"condition\": \"Brand New\", \"seller_info\": {\"name\": \"terashack\", \"review_count\": 59308, \"positive_feedback_percent\": 100}, \"is_auction\": false, \"buy_it_now\": false, \"free_returns\": true, \"sponsored\": true, \"prices\": [{\"value\": 9.99, \"raw\": \"$9.99\"}, {\"value\": 179.99, \"raw\": ...\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1703782939445
        }
      },
      "id": "9782fafa-9453-46be-b9d7-b33088f61ac8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the answer from this product query (the demo only works with 'memory cards' - you will need to sign up for their trial if you want to try any query with an API key), is about 16.5k tokens. When combined with the prompt, we won't have any other option than to use GPT-4-32k or GPT-4 turbo models. "
      ],
      "metadata": {},
      "id": "57cf8aaa-9a16-48ad-9846-bbacec82d52f"
    },
    {
      "cell_type": "code",
      "source": [
        "class MySimpleAPISearch(BaseTool):\n",
        "    \"\"\"Tool for simple API calls that doesn't require OpenAPI 3.0 specs\"\"\"\n",
        "    \n",
        "    name = \"@apisearch\"\n",
        "    description = \"useful when the questions includes the term: @apisearch.\\n\"\n",
        "\n",
        "    api_key: str\n",
        "    \n",
        "    def _run(self, query: str) -> str:\n",
        "        \n",
        "        params = {\n",
        "          'api_key': self.api_key,\n",
        "          'type': 'search',\n",
        "          'ebay_domain': 'ebay.com',\n",
        "          'search_term': query\n",
        "        }\n",
        "\n",
        "        # make the http GET request to Countdown API\n",
        "        api_result = requests.get('https://api.countdownapi.com/request', params)\n",
        "        \n",
        "        try:\n",
        "            response = json.dumps(api_result.json())\n",
        "        except Exception as e:\n",
        "            response = e\n",
        "        \n",
        "        return response\n",
        "            \n",
        "    async def _arun(self, query: str) -> str:\n",
        "        \"\"\"Use the tool asynchronously.\"\"\"\n",
        "        raise NotImplementedError(\"This Tool does not support async\")"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1703782939767
        }
      },
      "id": "67c51a32-13f5-4802-84cd-ce40b397cb1b"
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [MySimpleAPISearch(api_key='demo')]\n",
        "agent_executor = initialize_agent(tools, llm_1, \n",
        "                                  agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
        "                                  agent_kwargs={'prefix':APISEARCH_PROMPT_PREFIX}, \n",
        "                                  callback_manager=cb_manager,\n",
        "                                  handle_parsing_errors=True)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1703782940091
        }
      },
      "id": "c0daa409-a196-4eae-aaac-b4545d0e3280"
    },
    {
      "cell_type": "code",
      "source": [
        "#As LLMs responses are never the same, we do a for loop in case the answer cannot be parsed according to our prompt instructions\n",
        "for i in range(2):\n",
        "    try:\n",
        "        response = agent_executor.run('what is the price for SanDisk memory cards? give me the links please') \n",
        "        break\n",
        "    except Exception as e:\n",
        "        response = str(e)\n",
        "        continue\n",
        "\n",
        "printmd(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The user is asking for the price of SanDisk memory cards and also wants the links to the sources of this information. I will use the @apisearch tool to find this information.\nAction: @apisearch\nAction Input: SanDisk memory card price\nThe search did not return any results. I should try again with slightly different search terms.\nAction: @apisearch\nAction Input: price of SanDisk memory cards\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1703089543427
        }
      },
      "id": "71a1d824-7257-4a6b-8b0c-cd5176136ac7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {},
      "id": "56cbc405-26e2-471e-9626-2a0df07f5ddc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we learned about how to create very smart API agents for simple or complex APIs that use Swagger or OpenAPI specifications.\n",
        "We see, again, that the key to success is to use: Agents with Expert tools + GPT-4 + good prompts.\n",
        "\n",
        "As homework, try to create a shopping assistant for Etsy e-commerce site using the following API spec: (you will need to register for free and create an API-Key)\n",
        "\n",
        "- https://developers.etsy.com/documentation/\n",
        "- https://www.etsy.com/openapi/generated/oas/3.0.0.json"
      ],
      "metadata": {},
      "id": "7381ea5f-7269-4e1f-8b0c-1e2c04bd84c0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT\n",
        "\n",
        "The Next Notebook will guide you on how we stick everything together. How do we use the features of all notebooks and create a brain agent that can respond to any request accordingly."
      ],
      "metadata": {},
      "id": "02073623-91b4-40d6-8eaf-cb6d9c6a7a9a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}