{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Memory in LLMs"
      ],
      "metadata": {},
      "id": "01a8b5c0-87cb-4302-8e3c-dc809d0039fb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous Notebook, we successfully explored how OpenAI models can enhance the results from Azure Cognitive Search. \n",
        "\n",
        "However, we have yet to discover how to engage in a conversation with the LLM. With [Bing Chat](http://chat.bing.com/), for example, this is possible, as it can understand and reference the previous responses.\n",
        "\n",
        "There is a common misconception that GPT models have memory. This is not true. While they possess knowledge, they do not retain information from previous questions asked to them.\n",
        "\n",
        "In this Notebook, our goal is to illustrate how we can effectively \"endow the LLM with memory\" by employing prompts and context."
      ],
      "metadata": {},
      "id": "a2f73380-6395-4e9f-9c83-3f47a5d7e292"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings import AzureOpenAIEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.memory import CosmosDBChatMessageHistory\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "#custom libraries that we will use later in the app\n",
        "from common.utils import (\n",
        "    get_search_results,\n",
        "    update_vector_indexes,\n",
        "    model_tokens_limit,\n",
        "    num_tokens_from_docs,\n",
        "    num_tokens_from_string,\n",
        "    get_answer,\n",
        ")\n",
        "\n",
        "from common.prompts import COMBINE_CHAT_PROMPT_TEMPLATE\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "import logging\n",
        "\n",
        "# Get the root logger\n",
        "logger = logging.getLogger()\n",
        "# Set the logging level to a higher level to ignore INFO messages\n",
        "logger.setLevel(logging.WARNING)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1703870425032
        }
      },
      "id": "733c782e-204c-47d0-8dae-c9df7091ab23"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1703870425309
        }
      },
      "id": "6bc63c55-a57d-49a7-b6c7-0f18bca8199e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's start with the basics\n",
        "Let's use a very simple example to see if the GPT model of Azure OpenAI have memory. We again will be using langchain to simplify our code "
      ],
      "metadata": {},
      "id": "3dc72b22-11c2-4df0-91b8-033d01829663"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"Tell me some use cases for reinforcement learning\"\n",
        "FOLLOW_UP_QUESTION = \"Give me the main points of our conversation\""
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1703870425530
        }
      },
      "id": "3eef5dc9-8b80-4085-980c-865fa41fa1f6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "MODEL = \"gpt-35-turbo\"\n",
        "COMPLETION_TOKENS = 500\n",
        "# Create an OpenAI instance\n",
        "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5, max_tokens=COMPLETION_TOKENS)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1703870425971
        }
      },
      "id": "a00181d5-bd76-4ce4-a256-75ac5b58c60f"
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a very simple prompt template, just the question as is:\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"{question}\",\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1703870426230
        }
      },
      "id": "9502d0f1-fddf-40d1-95d2-a1461dcc498a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see what the GPT model responds\n",
        "#response = chain.run(QUESTION)\n",
        "#printmd(response)\n",
        "\n",
        "response = chain.run(QUESTION)\n",
        "printmd(response)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Sure! Here are some use cases for reinforcement learning:\n\n1. Game playing: Reinforcement learning has been successfully applied to game playing, such as playing chess, Go, or Atari games. DeepMind's AlphaGo is a famous example of reinforcement learning in action.\n\n2. Robotics: Reinforcement learning can be used to train robots to perform complex tasks, such as grasping objects, walking, or flying. It enables robots to learn from trial and error in real-world environments.\n\n3. Autonomous driving: Reinforcement learning can be used to train self-driving cars to make decisions, navigate traffic, and respond to various road conditions. It helps in optimizing driving behavior and improving safety.\n\n4. Recommendation systems: Reinforcement learning can be used to personalize recommendations for users in various domains, such as movies, music, or products. It helps in learning user preferences and optimizing recommendations over time.\n\n5. Energy management: Reinforcement learning can be used to optimize energy consumption and management in smart grids. It enables intelligent decision-making to balance energy generation, storage, and consumption.\n\n6. Healthcare: Reinforcement learning can be used to optimize treatment plans, drug dosage, and personalized medicine. It helps in learning optimal strategies for disease management and patient care.\n\n7. Finance: Reinforcement learning can be used for algorithmic trading, portfolio management, and risk assessment. It helps in learning optimal trading strategies and making informed investment decisions.\n\n8. Resource allocation: Reinforcement learning can be used to optimize resource allocation in various domains, such as transportation, logistics, or supply chain management. It helps in making efficient decisions to allocate resources effectively.\n\n9. Industrial control systems: Reinforcement learning can be used to optimize control and operation of industrial processes, such as chemical plants or manufacturing systems. It helps in learning optimal control policies and improving system performance.\n\n10. Natural language processing: Reinforcement learning can be used to improve dialogue systems, machine translation, or text summarization. It helps in learning to generate more accurate and context-aware responses.\n\nThese are just a few examples, and reinforcement learning has a wide range of applications across various domains."
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1703870429844
        }
      },
      "id": "c5c9903e-15c7-4e05-87a1-58e5a7917ba2"
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's ask a follow up question\n",
        "chain.run(FOLLOW_UP_QUESTION)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "'1. The topic of our conversation was about the upcoming project deadline.\\n2. We discussed the progress made so far and identified areas that need more attention.\\n3. We talked about potential strategies to meet the deadline and discussed the resources available.\\n4. We agreed on distributing tasks among team members and set specific targets for each.\\n5. We discussed the importance of effective communication and coordination within the team.\\n6. We addressed any concerns or challenges that may arise during the project and brainstormed possible solutions.\\n7. We concluded the conversation by setting a follow-up meeting to track progress and make any necessary adjustments.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1703870430818
        }
      },
      "id": "99acaf3c-ce68-4b87-b24a-6065b15ff9a8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, it doesn't remember what it just responded, sometimes it responds based only on the system prompt, or just randomly. This proof that the LLM does NOT have memory and that we need to give the memory as a a conversation history as part of the prompt, like this:"
      ],
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": []
      },
      "id": "a3e1c143-c95f-4566-a8b4-af8c42f08dd2"
    },
    {
      "cell_type": "code",
      "source": [
        "hist_prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"question\"],\n",
        "    template=\"\"\"\n",
        "                {history}\n",
        "                Human: '{question}\n",
        "                AI:\n",
        "            \"\"\"\n",
        "    )\n",
        "chain = LLMChain(llm=llm, prompt=hist_prompt)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1703870431302
        }
      },
      "id": "0946ce71-6285-432e-b011-9c2dc1ba7b8a"
    },
    {
      "cell_type": "code",
      "source": [
        "Conversation_history = \"\"\"\n",
        "Human: {question}\n",
        "AI: {response}\n",
        "\"\"\".format(question=QUESTION, response=response)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1703870431713
        }
      },
      "id": "6d088e51-e5eb-4143-b87d-b2be429eb864"
    },
    {
      "cell_type": "code",
      "source": [
        "printmd(chain.run({\"history\":Conversation_history, \"question\": FOLLOW_UP_QUESTION}))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Sure! Here are the main points of our conversation:\n\n- Reinforcement learning has various use cases, including game playing, robotics, autonomous driving, recommendation systems, energy management, healthcare, finance, resource allocation, industrial control systems, and natural language processing.\n- It is used in game playing to train AI agents to play chess, Go, or Atari games.\n- In robotics, reinforcement learning helps train robots to perform complex tasks in real-world environments.\n- It is used in autonomous driving to make decisions and navigate traffic, improving safety and optimizing driving behavior.\n- Reinforcement learning is used in recommendation systems to personalize recommendations for users in domains like movies, music, and products.\n- In energy management, it optimizes energy consumption and management in smart grids.\n- In healthcare, it helps optimize treatment plans, drug dosage, and personalized medicine.\n- In finance, reinforcement learning is used for algorithmic trading, portfolio management, and risk assessment.\n- It optimizes resource allocation in domains like transportation, logistics, and supply chain management.\n- In industrial control systems, it optimizes control and operation of industrial processes.\n- Reinforcement learning can improve natural language processing tasks like dialogue systems, machine translation, and text summarization.\n\nThese are the main points we discussed about the use cases of reinforcement learning."
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1703870432932
        }
      },
      "id": "d99e34ad-5539-44dd-b080-3ad05efd2f01"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bingo!**, so we now know how to create a chatbot using LLMs, we just need to keep the state/history of the conversation and pass it as context every time"
      ],
      "metadata": {},
      "id": "045e5af6-55d6-4353-b3f6-3275c95db00a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now that we understand the concept of memory via adding history as a context, let's go back to our GPT Smart Search engine"
      ],
      "metadata": {},
      "id": "eafd1694-0077-4aa8-bd01-e9f763ce36a3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Since Memory adds tokens to the prompt, we would need a better model that allows more space on the prompt\n",
        "MODEL = \"gpt-35-turbo-16k\"\n",
        "COMPLETION_TOKENS = 2000\n",
        "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5, max_tokens=COMPLETION_TOKENS)\n",
        "embedder = AzureOpenAIEmbeddings(deployment=\"text-embedding-ada-002\", chunk_size=1) "
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1703870433768
        }
      },
      "id": "ba257e86-fd90-4a51-a72d-27000913e8c2"
    },
    {
      "cell_type": "code",
      "source": [
        "index1_name = \"cogsrch-index-files\"\n",
        "# index2_name = \"cogsrch-index-csv\"\n",
        "index3_name = \"cogsrch-index-books-vector\"\n",
        "text_indexes = [index1_name]\n",
        "vector_indexes = [index+\"-vector\" for index in text_indexes] + [index3_name]"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1703870434058
        }
      },
      "id": "ef9f459b-e8b8-40b9-a94d-80c079968594"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Search in text-based indexes first and update vector indexes\n",
        "k=10 # Top k results per each text-based index\n",
        "ordered_results = get_search_results(QUESTION, text_indexes, k=k, reranker_threshold=1, vector_search=False)\n",
        "update_vector_indexes(ordered_search_results=ordered_results, embedder=embedder)\n",
        "\n",
        "# Search in all vector-based indexes available\n",
        "similarity_k = 5 # top results from multi-vector-index similarity search\n",
        "ordered_results = get_search_results(QUESTION, vector_indexes, k=k, vector_search=True,\n",
        "                                        similarity_k=similarity_k,\n",
        "                                        query_vector = embedder.embed_query(QUESTION))\n",
        "print(\"Number of results:\",len(ordered_results))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of results: 5\nCPU times: user 451 ms, sys: 44.1 ms, total: 495 ms\nWall time: 2.84 s\n"
        }
      ],
      "execution_count": 13,
      "metadata": {},
      "id": "b01852c2-6192-496c-adff-4270f9380469"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment the below line if you want to inspect the ordered results\n",
        "# ordered_results"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1703870436837
        }
      },
      "id": "ca500dd8-148c-4d8a-b58b-2df4c957459d"
    },
    {
      "cell_type": "code",
      "source": [
        "top_docs = []\n",
        "for key,value in ordered_results.items():\n",
        "    location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
        "    top_docs.append(Document(page_content=value[\"chunk\"], metadata={\"source\": location+os.environ['BLOB_SAS_TOKEN']}))\n",
        "        \n",
        "print(\"Number of chunks:\",len(top_docs))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of chunks: 5\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1703870437111
        }
      },
      "id": "9b2a3595-c3b7-4376-b9c5-0db7a42b3ee4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate number of tokens of our docs\n",
        "if(len(top_docs)>0):\n",
        "    tokens_limit = model_tokens_limit(MODEL) # this is a custom function we created in common/utils.py\n",
        "    prompt_tokens = num_tokens_from_string(COMBINE_CHAT_PROMPT_TEMPLATE) # this is a custom function we created in common/utils.py\n",
        "    context_tokens = num_tokens_from_docs(top_docs) # this is a custom function we created in common/utils.py\n",
        "    \n",
        "    requested_tokens = prompt_tokens + context_tokens + COMPLETION_TOKENS\n",
        "    \n",
        "    chain_type = \"map_reduce\" if requested_tokens > 0.9 * tokens_limit else \"stuff\"  \n",
        "    \n",
        "    print(\"System prompt token count:\",prompt_tokens)\n",
        "    print(\"Max Completion Token count:\", COMPLETION_TOKENS)\n",
        "    print(\"Combined docs (context) token count:\",context_tokens)\n",
        "    print(\"--------\")\n",
        "    print(\"Requested token count:\",requested_tokens)\n",
        "    print(\"Token limit for\", MODEL, \":\", tokens_limit)\n",
        "    print(\"Chain Type selected:\", chain_type)\n",
        "        \n",
        "else:\n",
        "    print(\"NO RESULTS FROM AZURE SEARCH\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "System prompt token count: 2480\nMax Completion Token count: 2000\nCombined docs (context) token count: 5085\n--------\nRequested token count: 9565\nToken limit for gpt-35-turbo-16k : 16384\nChain Type selected: stuff\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1703870437345
        }
      },
      "id": "c26d7540-feb8-4581-849e-003f4bf2a601"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Get the answer\n",
        "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Some use cases for reinforcement learning include:\n1. Searching for plannable domains to speed up reinforcement learning [1]\n2. Algorithms for reinforcement learning in routing [2]\n3. Using gradient descent methods for policy search in reinforcement learning [3]\n4. Reusing accumulated experience in reinforcement learning without a generative model of the environment [4]\n\nReferences:\n[1] Source: https://demodatasetsp.blob.core.windows.net/arxivcs/arxivcs/0212/0212025v1.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-01T22:05:56Z&st=2023-12-27T15:05:56Z&spr=https&sig=9%2BxiwXXov2K8qAvXz6ep6Z%2Fi3sh7g1wr8huIvhggyMs%3D\n[2] Source: https://demodatasetsp.blob.core.windows.net/arxivcs/arxivcs/0207/0207073v1.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-01T22:05:56Z&st=2023-12-27T15:05:56Z&spr=https&sig=9%2BxiwXXov2K8qAvXz6ep6Z%2Fi3sh7g1wr8huIvhggyMs%3D\n[3] Source: https://demodatasetsp.blob.core.windows.net/arxivcs/arxivcs/0105/0105027v1.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-01T22:05:56Z&st=2023-12-27T15:05:56Z&spr=https&sig=9%2BxiwXXov2K8qAvXz6ep6Z%2Fi3sh7g1wr8huIvhggyMs%3D\n[4] Source: https://demodatasetsp.blob.core.windows.net/arxivcs/arxivcs/0105/0105027v1.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-01T22:05:56Z&st=2023-12-27T15:05:56Z&spr=https&sig=9%2BxiwXXov2K8qAvXz6ep6Z%2Fi3sh7g1wr8huIvhggyMs%3D"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 22.2 ms, sys: 7.83 ms, total: 30 ms\nWall time: 8.51 s\n"
        }
      ],
      "execution_count": 17,
      "metadata": {},
      "id": "3ce6efa9-2b8f-4810-904d-5986b4ae0372"
    },
    {
      "cell_type": "markdown",
      "source": [
        "And if we ask the follow up question:"
      ],
      "metadata": {},
      "id": "27501f1b-7db0-4ee3-9cb1-e609254ffa3d"
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_answer(llm=llm, docs=top_docs,  query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "I'm sorry, but I don't have enough information to provide the main points of our conversation."
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1703870445722
        }
      },
      "id": "5cf5b323-3b9c-479b-8502-acfc4f7915dd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might get a different response from above, but it doesn't matter what response you get, it will be based on the context given, not on previous answers.\n",
        "\n",
        "Until now we just have the same as the prior Notebook 03: results from Azure Search enhanced by OpenAI model, with no memory\n",
        "\n",
        "**Now let's add memory to it:**\n",
        "\n",
        "Reference: https://python.langchain.com/docs/modules/memory/how_to/adding_memory_chain_multiple_inputs"
      ],
      "metadata": {},
      "id": "035fa6e6-226c-400f-a504-30255385f43b"
    },
    {
      "cell_type": "code",
      "source": [
        "# memory object, which is neccessary to track the inputs/outputs and hold a conversation.\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\")\n",
        "\n",
        "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type, \n",
        "                        memory=memory)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Reinforcement learning has a wide range of use cases across various domains. Here are some examples:\n\n1. **Game Playing**: Reinforcement learning has been successfully applied to game playing, where agents learn to make decisions and improve their strategies through trial and error. For example, AlphaGo, developed by DeepMind, used reinforcement learning to become a world champion in the game of Go.\n\n2. **Robotics**: Reinforcement learning is used in robotics to teach robots how to perform complex tasks and interact with their environment. Robots can learn to navigate, manipulate objects, and perform actions based on rewards and penalties.\n\n3. **Autonomous Vehicles**: Reinforcement learning is used in autonomous vehicles to make decisions about driving behavior, such as lane changing, merging, and navigating intersections. Agents can learn to optimize driving strategies based on safety and efficiency.\n\n4. **Recommendation Systems**: Reinforcement learning can be used to personalize recommendations for users in various domains, such as e-commerce, entertainment, and content platforms. Agents can learn to recommend items or content based on user preferences and feedback.\n\n5. **Resource Management**: Reinforcement learning can be applied to optimize the allocation and management of resources in various systems, such as energy grids, supply chains, and telecommunications networks. Agents can learn to make decisions that maximize efficiency and minimize costs.\n\n6. **Healthcare**: Reinforcement learning has the potential to improve healthcare outcomes by optimizing treatment plans, personalized medicine, and clinical decision-making. Agents can learn to make treatment recommendations based on patient data and medical guidelines.\n\nThese are just a few examples of the many possible use cases for reinforcement learning. The applications are diverse and can be tailored to specific domains and problem domains."
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1703870450909
        }
      },
      "id": "d98b876e-d264-48ae-b5ed-9801d6a9152b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we add a follow up question:\n",
        "response = get_answer(llm=llm, docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type, \n",
        "                      memory=memory)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Based on our conversation, here are the main points:\n\n1. Reinforcement learning has a wide range of use cases across various domains.\n2. Some examples of use cases for reinforcement learning include game playing, robotics, autonomous vehicles, recommendation systems, resource management, and healthcare.\n3. Reinforcement learning can be used to teach agents how to make decisions and improve their strategies through trial and error.\n4. It can be applied to tasks such as navigating, manipulating objects, making driving decisions, personalizing recommendations, optimizing resource allocation, and improving healthcare outcomes.\n5. Reinforcement learning algorithms often integrate planning methods to speed up learning and decision-making.\n6. Planning involves generating and evaluating different policies or actions based on a model of the environment.\n7. The Markov decision process (MDP) and partially observable Markov decision process (POMDP) are commonly used models for reinforcement learning.\n8. Policies in reinforcement learning define the actions to be taken based on the current state and history of interactions.\n9. The value of a policy is the expected return or reward obtained by following that policy.\n10. Off-line scenarios in reinforcement learning involve separating the data acquisition module from the optimization or learning module.\n11. In off-line scenarios, it is important to generalize from limited interaction experience to make judgments about untried behaviors.\n12. Importance sampling and likelihood ratio estimation can be used to estimate the value of policies and generalize from limited experience.\n13. The estimation of policy value can be used to select among candidate classes of policies with different complexities.\n\nThese points summarize the main topics we discussed regarding reinforcement learning and its applications. Let me know if there's anything else I can help you with.\n\nSources:\n[1]<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/arxivcs/0212/0212025v1.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-01T22:05:56Z&st=2023-12-27T15:05:56Z&spr=https&sig=9%2BxiwXXov2K8qAvXz6ep6Z%2Fi3sh7g1wr8huIvhggyMs%3D\" target=\"_blank\">Source 1</a></sup>\n[2]<sup><a href=\"https://demodatasetsp.blob.core.windows.net/books/Made_To_Stick.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-01T22:05:56Z&st=2023-12-27T15:05:56Z&spr=https&sig=9%2BxiwXXov2K8qAvXz6ep6Z%2Fi3sh7g1wr8huIvhggyMs%3D\" target=\"_blank\">Source 2</a></sup>\n[3]<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/arxivcs/0207/0207073v1.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-01T22:05:56Z&st=2023-12-27T15:05:56Z&spr=https&sig=9%2BxiwXXov2K8qAvXz6ep6Z%2Fi3sh7g1wr8huIvhggyMs%3D\" target=\"_blank\">Source 3</a></sup>\n[4]<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/arxivcs/0105/0105027v1.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-01T22:05:56Z&st=2023-12-27T15:05:56Z&spr=https&sig=9%2BxiwXXov2K8qAvXz6ep6Z%2Fi3sh7g1wr8huIvhggyMs%3D\" target=\"_blank\">Source 4</a></sup>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1703870463767
        }
      },
      "id": "bf28927b-d9ee-4412-bb07-13e055e832a7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Another follow up query\n",
        "response = get_answer(llm=llm, docs=top_docs, query=\"Thank you\", language=\"English\", chain_type=chain_type,  \n",
        "                      memory=memory)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "I'm sorry, but I couldn't find any information about the main points of our conversation in the provided sources. Is there anything else I can help you with?"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1703870464827
        }
      },
      "id": "3830b0b8-0ca2-4d0a-9747-f6273368002b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might get a different answer on the above cell, and it is ok, this bot is not yet well configured to answer any question that is not related to its knowledge base, including salutations.\n",
        "\n",
        "Let's check our memory to see that it's keeping the conversation"
      ],
      "metadata": {},
      "id": "111e732b-3c8c-4df3-8fcb-c3d01e7bec74"
    },
    {
      "cell_type": "code",
      "source": [
        "memory.buffer"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "'Human: Tell me some use cases for reinforcement learning\\nAI: Reinforcement learning has a wide range of use cases across various domains. Here are some examples:\\n\\n1. **Game Playing**: Reinforcement learning has been successfully applied to game playing, where agents learn to make decisions and improve their strategies through trial and error. For example, AlphaGo, developed by DeepMind, used reinforcement learning to become a world champion in the game of Go.\\n\\n2. **Robotics**: Reinforcement learning is used in robotics to teach robots how to perform complex tasks and interact with their environment. Robots can learn to navigate, manipulate objects, and perform actions based on rewards and penalties.\\n\\n3. **Autonomous Vehicles**: Reinforcement learning is used in autonomous vehicles to make decisions about driving behavior, such as lane changing, merging, and navigating intersections. Agents can learn to optimize driving strategies based on safety and efficiency.\\n\\n4. **Recommendation Systems**: Reinforcement learning can be used to personalize recommendations for users in various domains, such as e-commerce, entertainment, and content platforms. Agents can learn to recommend items or content based on user preferences and feedback.\\n\\n5. **Resource Management**: Reinforcement learning can be applied to optimize the allocation and management of resources in various systems, such as energy grids, supply chains, and telecommunications networks. Agents can learn to make decisions that maximize efficiency and minimize costs.\\n\\n6. **Healthcare**: Reinforcement learning has the potential to improve healthcare outcomes by optimizing treatment plans, personalized medicine, and clinical decision-making. Agents can learn to make treatment recommendations based on patient data and medical guidelines.\\n\\nThese are just a few examples of the many possible use cases for reinforcement learning. The applications are diverse and can be tailored to specific domains and problem domains.\\nHuman: Give me the main points of our conversation\\nAI: Based on our conversation, here are the main points:\\n\\n1. Reinforcement learning has a wide range of use cases across various domains.\\n2. Some examples of use cases for reinforcement learning include game playing, robotics, autonomous vehicles, recommendation systems, resource management, and healthcare.\\n3. Reinforcement learning can be used to teach agents how to make decisions and improve their strategies through trial and error.\\n4. It can be applied to tasks such as navigating, manipulating objects, making driving decisions, personalizing recommendations, optimizing resource allocation, and improving healthcare outcomes.\\n5. Reinforcement learning algorithms often integrate planning methods to speed up learning and decision-making.\\n6. Planning involves generating and evaluating different policies or actions based on a model of the environment.\\n7. The Markov decision process (MDP) and partially observable Markov decision process (POMDP) are commonly used models for reinforcement learning.\\n8. Policies in reinforcement learning define the actions to be taken based on the current state and history of interactions.\\n9. The value of a policy is the expected return or reward obtained by following that policy.\\n10. Off-line scenarios in reinforcement learning involve separating the data acquisition module from the optimization or learning module.\\n11. In off-line scenarios, it is important to generalize from limited interaction experience to make judgments about untried behaviors.\\n12. Importance sampling and likelihood ratio estimation can be used to estimate the value of policies and generalize from limited experience.\\n13. The estimation of policy value can be used to select among candidate classes of policies with different complexities.\\n\\nThese points summarize the main topics we discussed regarding reinforcement learning and its applications. Let me know if there\\'s anything else I can help you with.\\n\\nSources:\\n[1]<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/arxivcs/0212/0212025v1.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-01T22:05:56Z&st=2023-12-27T15:05:56Z&spr=https&sig=9%2BxiwXXov2K8qAvXz6ep6Z%2Fi3sh7g1wr8huIvhggyMs%3D\" target=\"_blank\">Source 1</a></sup>\\n[2]<sup><a href=\"https://demodatasetsp.blob.core.windows.net/books/Made_To_Stick.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-01T22:05:56Z&st=2023-12-27T15:05:56Z&spr=https&sig=9%2BxiwXXov2K8qAvXz6ep6Z%2Fi3sh7g1wr8huIvhggyMs%3D\" target=\"_blank\">Source 2</a></sup>\\n[3]<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/arxivcs/0207/0207073v1.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-01T22:05:56Z&st=2023-12-27T15:05:56Z&spr=https&sig=9%2BxiwXXov2K8qAvXz6ep6Z%2Fi3sh7g1wr8huIvhggyMs%3D\" target=\"_blank\">Source 3</a></sup>\\n[4]<sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/arxivcs/0105/0105027v1.pdf?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2024-07-01T22:05:56Z&st=2023-12-27T15:05:56Z&spr=https&sig=9%2BxiwXXov2K8qAvXz6ep6Z%2Fi3sh7g1wr8huIvhggyMs%3D\" target=\"_blank\">Source 4</a></sup>\\nHuman: Thank you\\nAI: I\\'m sorry, but I couldn\\'t find any information about the main points of our conversation in the provided sources. Is there anything else I can help you with?'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1703870465131
        }
      },
      "id": "1279692c-7eb0-4300-8a66-c7025f02c318"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using CosmosDB as persistent memory\n",
        "\n",
        "In previous cell we have added local RAM memory to our chatbot. However, it is not persistent, it gets deleted once the app user's session is terminated. It is necessary then to use a Database for persistent storage of each of the bot user conversations, not only for Analytics and Auditing, but also if we wisg to provide recommendations. \n",
        "\n",
        "Here we will store the conversation history into CosmosDB for future auditing purpose.\n",
        "We will use a class in LangChain use CosmosDBChatMessageHistory, see [HERE](https://python.langchain.com/en/latest/_modules/langchain/memory/chat_message_histories/cosmos_db.html)"
      ],
      "metadata": {},
      "id": "87405173"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CosmosDB instance from langchain cosmos class.\n",
        "cosmos = CosmosDBChatMessageHistory(\n",
        "    cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
        "    cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
        "    cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
        "    connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
        "    session_id=\"Agent-Test-Session\" + str(random.randint(1, 1000)),\n",
        "    user_id=\"Agent-Test-User\" + str(random.randint(1, 1000))\n",
        "    )\n",
        "\n",
        "# prepare the cosmosdb instance\n",
        "cosmos.prepare_cosmos()"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1703870465715
        }
      },
      "id": "c7131daa"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create or Memory Object\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\",chat_memory=cosmos)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1703870465952
        }
      },
      "id": "d87cc7c6-5ef1-4492-b133-9f63a392e223"
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing using our Question\n",
        "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type, \n",
        "                        memory=memory)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Markdown object>",
            "text/markdown": "Reinforcement learning has a wide range of use cases. Here are a few examples:\n\n1. **Game playing**: Reinforcement learning has been successfully applied to games such as chess, Go, and poker. By learning from experience and optimizing strategies, reinforcement learning algorithms have achieved superhuman performance in these games.\n\n2. **Robotics**: Reinforcement learning can be used to train robots to perform complex tasks, such as grasping objects, navigating through environments, and even playing sports. By learning from trial and error, robots can improve their actions and adapt to different situations.\n\n3. **Autonomous vehicles**: Reinforcement learning can be used to train self-driving cars and drones. By learning from real-world data and simulations, these vehicles can learn to navigate roads, avoid obstacles, and make safe and efficient decisions.\n\n4. **Recommendation systems**: Reinforcement learning can be used to personalize recommendations for users in various domains, such as e-commerce, music streaming, and online advertising. By learning from user feedback and interactions, these systems can optimize recommendations to improve user satisfaction.\n\n5. **Resource management**: Reinforcement learning can be used to optimize the allocation of resources in various domains, such as energy grids, transportation systems, and supply chains. By learning from historical data and real-time information, these systems can make intelligent decisions to maximize efficiency and minimize costs.\n\nThese are just a few examples of the many use cases for reinforcement learning. Its ability to learn from experience and optimize actions makes it a powerful tool in various domains. If you need more information or have specific questions about any of these use cases, feel free to ask!"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1703870469901
        }
      },
      "id": "27ceb47a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we add a follow up question:\n",
        "response = get_answer(llm=llm, docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type, \n",
        "                      memory=memory)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1703869671814
        }
      },
      "id": "1a5ff826"
    },
    {
      "cell_type": "code",
      "source": [
        "# Another follow up query\n",
        "response = get_answer(llm=llm, docs=top_docs, query=\"Thank you\", language=\"English\", chain_type=chain_type,  \n",
        "                      memory=memory)\n",
        "printmd(response['output_text'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1703869674866
        }
      },
      "id": "be1620fa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check our Azure CosmosDB to see the whole conversation\n"
      ],
      "metadata": {},
      "id": "cdc5ac98"
    },
    {
      "cell_type": "code",
      "source": [
        "#load message from cosmosdb\n",
        "cosmos.load_messages()\n",
        "cosmos.messages"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1703869675311
        }
      },
      "id": "e1d7688a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![CosmosDB Memory](./images/cosmos-chathistory.png)"
      ],
      "metadata": {},
      "id": "f5e30694-ae2a-47bb-a5c7-db51ecdbba1e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "##### Adding memory to our application allows the user to have a conversation, however this feature is not something that comes with the LLM, but instead, memory is something that we must provide to the LLM in form of context of the question.\n",
        "\n",
        "We added persitent memory using CosmosDB.\n",
        "\n",
        "We also can notice that the current chain that we are using is smart, but not that much. Although we have given memory to it, it searches for similar docs everytime, regardless of the input and it struggles to respond to prompts like: Hello, Thank you, Bye, What's your name, What's the weather and any other task that is not search in the knowledge base.\n",
        "\n",
        "\n",
        "## <u>Important Note</u>:<br>\n",
        "As we proceed, while all the code will remain compatible with GPT-3.5 models, we highly recommend transitioning to GPT-4. Here's why:\n",
        "\n",
        "**GPT-3.5-Turbo** can be likened to a 7-year-old child. You can provide it with concise instructions, but it frequently struggles to follow them accurately. Additionally, its limited memory can make sustained conversations challenging.\n",
        "\n",
        "**GPT-3.5-Turbo-16k** resembles the same 7-year-old, but with an increased attention span for longer instructions. However, it still faces difficulties accurately executing them about half the time.\n",
        "\n",
        "**GPT-4** exhibits the capabilities of a 10-12-year-old child. It possesses enhanced reasoning skills and more consistently adheres to instructions. While its memory retention for instructions is moderate, it excels at following them.\n",
        "\n",
        "**GPT-4-32k** is akin to the 10-12-year-old child with an extended memory. It comprehends lengthy sets of instructions and engages in meaningful conversations. Thanks to its robust memory, it offers detailed responses.\n",
        "\n",
        "Understanding this analogy above will become clearer as you complete the final notebook.\n"
      ],
      "metadata": {},
      "id": "6789cada-23a3-451a-a91a-0906ceb0bd14"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT\n",
        "We know now how to do a Smart Search Engine that can power a chatbot!! great!\n",
        "\n",
        "But, does this solve all the possible scenarios that a virtual assistant will require?  **What about if the answer to the Smart Search Engine is not related to text, but instead requires to look into tabular data?** The next notebook explains and solves the tabular problem and the concept of Agents"
      ],
      "metadata": {},
      "id": "c629ebf4-aced-45b7-a6a2-315810d37d48"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "6d4d9da4-3918-4da6-b235-a3320f0dcb12"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}