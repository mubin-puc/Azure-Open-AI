{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q&A against a SQL Database (Azure SQL, Azure Fabric, Synapse, SQL Managed Instance, etc)"
      ],
      "metadata": {},
      "id": "66ab3cc5-aee4-415a-9391-1e5d37ccaf1d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we know (from the prior Notebook) how to query tabular data on a CSV file, let's try now to keep the data at is source and ask questions directly to a SQL Database.\n",
        "The goal of this notebook is to demonstrate how a LLM so advanced as GPT-4 can understand a human question and translate that into a SQL query to get the answer. \n",
        "\n",
        "We will be using the Azure SQL Server that you created on the initial deployment. However the same code below works with any SQL database like Synapse for example. The server should be created on the Resource Group where the Azure Cognitive Search service is located.\n",
        "\n",
        "Let's begin.."
      ],
      "metadata": {},
      "id": "306fc0a9-4044-441d-9ba7-f54f32e6ea9f"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import pyodbc\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.sql_database import SQLDatabase\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "\n",
        "from common.prompts import MSSQL_PROMPT, MSSQL_AGENT_PREFIX, MSSQL_AGENT_FORMAT_INSTRUCTIONS\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1703089034509
        }
      },
      "id": "c1fb79a3-4856-4721-988c-112813690a90"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1703089034841
        }
      },
      "id": "258a6e99-2d4f-4147-b8ee-c64c85296181"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install MS SQL DB driver in your machine"
      ],
      "metadata": {},
      "id": "1e8e0b32-a6b5-4b1c-943d-e57b737213fa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need the driver installed on this compute in order to talk to the SQL DB, so run the below cell once<br>\n",
        "Reference: https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver16&tabs=ubuntu18-install%2Calpine17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline"
      ],
      "metadata": {},
      "id": "9a353df6-0966-4e43-a914-6a2856eb140a"
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo ./download_odbc_driver.sh"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1703089035109
        }
      },
      "id": "65fbffc7-e149-4eb3-a4db-9f114b06f205"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Azure SQL DB with the Covid Tracking CSV Data"
      ],
      "metadata": {},
      "id": "35e30fa1-877d-4d3b-80b0-e17459c1e4f4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Azure SQL Database is currently empty, so we need to fill it up with data. Let's use the same data on the Covid CSV filed we used on the prior Notebook, that way we can compare results and methods. \n",
        "For this, you will need to type below the credentials you used at creation time."
      ],
      "metadata": {},
      "id": "b4352dca-7159-4e41-983d-2c6951cf18db"
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.engine.url import URL\n",
        "\n",
        "db_config = {\n",
        "                'drivername': 'mssql+pyodbc',\n",
        "                'username': os.environ[\"SQL_SERVER_USERNAME\"] +'@'+ os.environ[\"SQL_SERVER_NAME\"],\n",
        "                'password': os.environ[\"SQL_SERVER_PASSWORD\"],\n",
        "                'host': os.environ[\"SQL_SERVER_NAME\"],\n",
        "                'port': 1433,\n",
        "                'database': os.environ[\"SQL_SERVER_DATABASE\"],\n",
        "                'query': {'driver': 'ODBC Driver 17 for SQL Server'}\n",
        "            }\n",
        "\n",
        "# Create a URL object for connecting to the database\n",
        "db_url = URL.create(**db_config)\n",
        "\n",
        "# Print the resulting URL string\n",
        "# print(db_url)\n",
        "\n",
        "# Connect to the Azure SQL Database using the URL string\n",
        "engine = create_engine(db_url)\n",
        "\n",
        "# Test the connection\n",
        "try:\n",
        "    conn = engine.connect()\n",
        "    print(\"Connection successful!\")\n",
        "    result = engine.execute(\"SELECT @@Version\")\n",
        "    for row in result:\n",
        "        print(row)\n",
        "    conn.close()\n",
        "    \n",
        "except OperationalError:\n",
        "    print(\"Connection failed.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Connection successful!\n('Microsoft SQL Azure (RTM) - 12.0.2000.8 \\n\\tNov  2 2023 01:40:17 \\n\\tCopyright (C) 2022 Microsoft Corporation\\n',)\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_15748/2845560204.py:27: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n  result = engine.execute(\"SELECT @@Version\")\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1703089035537
        }
      },
      "id": "26739d89-e075-4098-ab38-92cccf9f9425"
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV file into a pandas dataframe\n",
        "csv_path = \"./data/all-states-history.csv\"\n",
        "df = pd.read_csv(csv_path).fillna(value = 0)\n",
        "\n",
        "# Infer column names and data types\n",
        "column_names = df.columns.tolist()\n",
        "column_types = df.dtypes.to_dict()\n",
        "\n",
        "# Generate SQL statement to create table\n",
        "table_name = 'covidtracking'\n",
        "\n",
        "create_table_sql = f\"CREATE TABLE {table_name} (\"\n",
        "for name, dtype in column_types.items():\n",
        "    if dtype == 'object':\n",
        "        create_table_sql += f\"{name} VARCHAR(MAX), \"\n",
        "    elif dtype == 'int64':\n",
        "        create_table_sql += f\"{name} INT, \"\n",
        "    elif dtype == 'float64':\n",
        "        create_table_sql += f\"{name} FLOAT, \"\n",
        "    elif dtype == 'bool':\n",
        "        create_table_sql += f\"{name} BIT, \"\n",
        "    elif dtype == 'datetime64[ns]':\n",
        "        create_table_sql += f\"{name} DATETIME, \"\n",
        "create_table_sql = create_table_sql[:-2] + \")\"\n",
        "\n",
        "try:\n",
        "    #Createse the table in Azure SQL\n",
        "    engine.execute(create_table_sql)\n",
        "    print(\"Table\",table_name,\"succesfully created\")\n",
        "    # Insert data into SQL Database\n",
        "    lower = 0\n",
        "    upper = 1000\n",
        "    limit = df.shape[0]\n",
        "\n",
        "    while lower < limit:\n",
        "        df[lower:upper].to_sql(table_name, con=engine, if_exists='append', index=False)\n",
        "        print(\"rows:\", lower, \"-\", upper, \"inserted\")\n",
        "        lower = upper\n",
        "        upper = min(upper + 1000, limit)\n",
        "\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Table covidtracking succesfully created\nrows: 0 - 1000 inserted\nrows: 1000 - 2000 inserted\nrows: 2000 - 3000 inserted\nrows: 3000 - 4000 inserted\nrows: 4000 - 5000 inserted\nrows: 5000 - 6000 inserted\nrows: 6000 - 7000 inserted\nrows: 7000 - 8000 inserted\nrows: 8000 - 9000 inserted\nrows: 9000 - 10000 inserted\nrows: 10000 - 11000 inserted\nrows: 11000 - 12000 inserted\nrows: 12000 - 13000 inserted\nrows: 13000 - 14000 inserted\nrows: 14000 - 15000 inserted\nrows: 15000 - 16000 inserted\nrows: 16000 - 17000 inserted\nrows: 17000 - 18000 inserted\nrows: 18000 - 19000 inserted\nrows: 19000 - 20000 inserted\nrows: 20000 - 20780 inserted\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1703089060980
        }
      },
      "id": "acaf202c-33a1-4105-b506-c26f2080c1d8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query with LLM"
      ],
      "metadata": {},
      "id": "33ad46af-11a4-41a6-94af-15509fd9e16c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: We are here using Azure SQL, however the same code will work with Synapse, SQL Managed instance, or any other SQL engine. You just need to provide the right ENV variables and it will connect succesfully."
      ],
      "metadata": {},
      "id": "ea2ef524-565a-4f28-9955-fce0d01bbe21"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create or LLM Langchain object using GPT-4 deployment\n",
        "# Again we need GPT-4. It is necesary in the use of Agents. GPT-35-Turbo will make many mistakes.\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4\", temperature=0, max_tokens=500)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1703089061507
        }
      },
      "id": "7faef3c0-8166-4f3b-a5e3-d30acfd65fd3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create the db object\n",
        "db = SQLDatabase.from_uri(db_url)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {},
      "id": "6cbe650c-9e0a-4209-9595-de13f2f1ee0a"
    },
    {
      "cell_type": "code",
      "source": [
        "# Natural Language question (query)\n",
        "QUESTION = \"How may patients were hospitalized during July 2020 in Texas, and nationwide as the total of all states? Use the hospitalizedIncrease column\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "ae80c022-415e-40d1-b205-1744a3164d70"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SQL Agent"
      ],
      "metadata": {},
      "id": "95052aba-d0c5-4883-a0b6-70c20e236b6a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use an agent now and see how ReAct framework solves the problem."
      ],
      "metadata": {},
      "id": "eb8b1352-d6d7-4319-a0b8-ae7b9c2fd234"
    },
    {
      "cell_type": "code",
      "source": [
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "\n",
        "agent_executor = create_sql_agent(\n",
        "    prefix=MSSQL_AGENT_PREFIX,\n",
        "    format_instructions = MSSQL_AGENT_FORMAT_INSTRUCTIONS,\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    top_k=30,\n",
        "    verbose=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "2b51fb36-68b5-4770-b5f1-c042a08e0a0f"
    },
    {
      "cell_type": "code",
      "source": [
        "# As we know by now, Agents use expert/tools. Let's see which are the tools for this SQL Agent\n",
        "agent_executor.agent.allowed_tools"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "21c6c6f5-4a14-403f-a1d0-fe6b0c34a563"
    },
    {
      "cell_type": "code",
      "source": [
        "# And let's see now our clever crafted prompt\n",
        "printmd(agent_executor.agent.llm_chain.prompt.template)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "1cae3488-5334-4fbb-ab97-a710af07f966"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2):\n",
        "    try:\n",
        "        response = agent_executor.run(QUESTION) \n",
        "        break\n",
        "    except Exception as e:\n",
        "        response = str(e)\n",
        "        continue"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "6d7bb8cf-8661-4174-8185-c64b4b20670d"
    },
    {
      "cell_type": "code",
      "source": [
        "printmd(response)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "f23d2135-2199-474e-ae83-455aefc9b93b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT NOTE**: If you don't specify the column name on the question, runing the above cell multiple times will yield diferent results some times. <br>\n",
        "The reason is:\n",
        "The column names are ambiguous, hence it is hard even for Humans to discern what are the right columns to use"
      ],
      "metadata": {},
      "id": "cfef208f-321c-490e-a50e-e92602daf125"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {},
      "id": "56cbc405-26e2-471e-9626-2a0df07f5ddc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we achieved our goal of Asking a Question in natural language to a dataset located on a SQL Database.  We did this by using purely prompt engineering (Langchain does it for us) and the cognitive power of GPT-4.\n",
        "\n",
        "This process shows why it is NOT necessary to move the data from its original source as long as the source has an API and a common language we can use to interface with. GPT-4 has been trained on the whole public Github corpus, so it can pretty much understand most of the coding and database query languages that exists out there. "
      ],
      "metadata": {},
      "id": "7381ea5f-7269-4e1f-8b0c-1e2c04bd84c0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT\n",
        "\n",
        "The Next Notebook will show you how to create a custom REACT agent that connects to the internet using BING SEARCH API to answer questions grounded on search results with citations. Basically a clone of Bing Chat."
      ],
      "metadata": {},
      "id": "02073623-91b4-40d6-8eaf-cb6d9c6a7a9a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}